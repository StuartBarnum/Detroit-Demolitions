---
title: "Predicting Blight in Detroit"
author: "Stuart Barnum"
date: "5/17/2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#####My aim in this project is to gain insight into patterns of urban blight, using open data sets published by the city of Detroit. Blight is understood in terms of issues related to buildings: citations for offenses such as failure to maintain a building or its grounds, blight-related complaints to a city-run hotline, local crime rates, and indicatations that the building is or was likely to be demolished. A building is deemed to have become irredemably blighted if city records indicate that the building was either demolished or likely to be demolished. Given this operational definition, I trained a variety of algorithms for predicting which buildings will become irredemably blighted. Although as many many as 15 predicitors appear to be at least somewhat effective as predictors---removing any one them appears to make make the most effective models at least somewhat less predictive---two of the predictors stand out as most effective: the numer of buildings, other than the building for which the prediction is taking place, within 200 meters that have have become irredemably blighted and the number of vacant lots within 200 meters. Using a decision tree to predict on the basis these variables alone consistently produced a model with 70% predictive accuracy. The more sophisticated approaches, random forest and adaboost, made use of all 15 of the variables and produced predictive accuracy of roughly 73%.

#### General methods
After a significant aount of data cleaning (as described in the next section), one of the first tasks in this project was to define a list of buildings. This could be done in one of at least two ways. In the first, suggested as a possible method in the instructions for this assignment, buildings might be identified with clusters of incidencts such as, perhaps, recorded crime indidents and citations for blight. I elected not to used this method for a number of reasons. The first reason is the possibility that there may be clusters of incidents associated with nonbuildings such as vacant lots and parks, and the possibility that there may be buildings at which there were very few or no incidents. As it would be impossible to identify all or most of the cases of either of these types, such cases may distort the analysis. Another reason was the availability of a relatively clean set of parcel (property lot) data, which included both geographical information about the parcels and information about any buildings on the parcels. Buildings can thus be represented in terms of a subset of these parcels. One of the drawbacks of this latter approach is that some of the parcels contain, or have contained, more than one building. And although it would be possible to eliminate from the data the parcels that, according to the data, *currently* contain more than one building, it is not not possibe to determine from the available data the parcels that have, in the past, contained more than one building (for the cases in which, for example, all of the buildings within a parcel have been demolished). Although either of the two methods may provide valuable insight, I elected to use the parcel data. The analysis was done on parcels that have recently contained, or have contained (since May of 2016) at least one building. (For example, although the data may indicate that no building currently exists on a given parcel, the data may indicate that a building on that parcel was dismantled in 2017, thus indicating that a building existed on that parcel such May of 2016.)

The next step in the analysis was to assign a set of labels, irredeamably blighted or not irredeamably blighted (henceforth simply "blighted" or "not blighted"), to the buildings. A building is deemed to be or have been blighted if it (1) was demolished, as indicated in an online list of buildings that have been demolished under the Detroit Demolitions Program (see https://data.detroitmi.gov/Property-Parcels/Detroit-Demolitions/rv44-e9di), (2) is contained in a list of upcoming demolitions under this program (see https://data.detroitmi.gov/Property-Parcels/Upcoming-Demolitions/tsqq-qtet) or (3) has a demolition permit associated with it (see https://data.detroitmi.gov/Property-Parcels/Building-Permits/xw2a-a7tf, in which the demolition permits are "building permits" for which the specified type is "dismantle"). I found it useful to use all of these datasets because there were reasons to believe that any one of them would fail to list significant numbers of blighted parcels. For example, the documentation associated with the completed demolitions datset indicated that the dataset fails to include some demolitions that were completed on an emergency basis. On the other hand, there are a significant number of buildings listed in the completed demolitions dataset that, based on the demolitions permits data, appear to not have had demolition permits associated with them, thus suggesting that the demolitions permits data is also incomplete. 

I should note that one possible fault in my approach to the labeling is with the fact that we used the demolitions permits data within our operational construal of blight. After all, for example, a wealthy resident might purchase an impeccably maintained home and then demolish it (with the requisite permit) to build a larger home. Likewise in the case of other buildings demolished in order to make room for other buildings. With this issue in mind, I restricted my analyis to those areas within Detroit that that have been identified as Hardest Hit Areas (see http://d3-d3.opendata.arcgis.com/datasets/383eb730952e470389f09617b5448026_0), for which federal funding is available for the demolition program. The assumption, here, is that, in such areas, a smaller proportion of the buildings that were torn down were sound (non-blighted) buildings that were, again, torn down simply to make room for other buildings (or parking lots, etc.).

Another matter of fundamental methods concerns the manner of association of the various potential predictors, such as numbers of blight-related citations associated with a particular building, with the relevant buildings. To make the associations, I used both spatial relationships and, where both necessary and possible, parcel numbers. For example, each record of a blight-related citation includes both a parcel number (identifier of the parcel) and a pair of latitude and longitude coordinates. If the position indicated by the coordinates was within a certain parcel, than that parcel was assumed to be the parcel associated with the citation. Otherwise, if an association could be made by means of identity of parcel numbers (the parcel number for a buildings the parcel number recorded with the citation), then the parcel thus associated was deemed to be the parcel associated with the citation. Other associations were made merely by means of geometric relationships. For example, recorded crime incidents, divided between violent crimes and property crimes, were associated with parcels in virtue of spacial proximity of 200 meters. 

#### Data munging and cleaning
The project was implemented in R and, at the data munging and cleaning stages, made extensive use of the tidyverse packages for data manipulation, ggmap for investigative visual maps and for geocoding in cases of missing position coordinates, and the sf package for handling spacial information and relationships. The R sf package provides an implementation of the simple features standard, ISO 19125-1:2004, for representing real-world objects in computers. Data frames in which spatial information is thus represented become simple features data frames, and it was possible to read the shapefile-format parcels dataset (see https://data.detroitmi.gov/Property-Parcels/Parcel-Map/fxkw-udwf/data) directly into a simple features dataframe. Likewise in the case of datasets I used for the hardest hit areas of and for the council districts---these relatively small files, in the form of simple maps of of the geometries of the respective areas of the city, were read directing into the simple features format. The other datasets, containing geographic point information, were converted into simple features data frames after I had both eliminated some geographical coordinate information that was clearly incorrect (e.g. blight citations for which the coordinate information indicated a position well outside of Detroit) and, where possible, filled in the missing coordinate information by means of the ggmap `geocode` function, which accessess the Google API for geocoding. Among the data in all of the datasets I used in this project, a total of roughly 5 thousand locations were geocoded. Data for which it was impossible to obtain usable location information was discarded. The conversion into an sf data frame also required some string manipulation, of the raw coordinate information. The coordinate reference system (providing the mapping of coordinates to locations) for all of the sf data frames was 4326, which is standardly used in GPS systems. (See https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/OverviewCoordinateReferenceSystems.pdf for a brief overview of coordinate reference systems.)

Another aspect of the data cleaning involved the parcels dataset. Two notable issues in this data were (1) identity of the parcel numbers among pairs of rows for which the parcel geometries were disjoint (non-overlapping) and (2) identity of the space covered by certain pairs of rows for which the parcel numbers were distinct. Although there were less than 100 pairs of either of these types, I addressed these issues as follows. For pairs of the former type (1), I made the parcel numbers (represented as strings in the data) distinct by appending unique identifiers at the end. For pairs of the latter type (2), I eliminated one of elements of each pair from the data. All of these cases (both (1) and (2)) were identified by means of the `sf` function `st_join`, by which one may implement SQL-like joins on the basis of spatial relationships. This required that the spherical representation of the latitude and longitude coordinates be projected into a plane, which, given the relatively small size of the city of Detroit in relation to Earth, provides a roughly accurate reresentation.

Another aspect of the parcels data that I investigated carefully was several thousand pairs of parcels that, according to an application of st_join, overalapped. I plotted a random sample of 100 of these pairs of parcels and found no evidence of overlap in the plots. I concluded that the apparent overlap may have been due to the projection (perhaps imperfect projection) of the spherical representation (coordinate representation system 4326 as per above) into a flat representation, and was likely not a problematic issue in my data.

After the various investigative and cleaning steps such as the obove were completed, I decided to restrict my analysis to those parcels in the Hardest Hit Areas, and so I cut out all of the parcels that were not within one of these areas (using, again, st_join). I constructed a set of labels for the remaining parcels, consisting of, for each parcel, the parcel number and the correct value with respect to blight (blighted or not blighted). I then cut out most of the rows in the labels dataset for which the value with respect to blight indicated *not blighted*, so as to create a relative ballance between positive instances (blighted) and negative instanced (not blighted). The parcels thus removed from the data were selected at random.

#### Construction of a tallies dataset
The predictive models that were eventually constructed in this project used data in the form of tallies (and other sums) from the data that had been processed as described above. All of the tallies were calculated using SQL-style joins on the basis of spatial relationships (st_join, again) and then, as in SQL, grouping and and counting the relevant results (using the R dplyr package). In the applications of st_join, there were two types of tallies. In the first, I simply looked for incidents, such as citations for failure to maintain a property, occuring within a parcel. The other type of application of st_join involved looking for incidents that were within a certain distance from a parcel. In the latter type of case, I created a "buffer" around each parcel using the sf operation st_buffer, thus expanding each each of the parcels by a certain distance, depending on what seemed reasonable, given what I was attempting to count. With the parcels thus expanded, I applied st_join, now looking for incidents (and some other entities such as vacant lots) within the expanded parcels. At the end of all of this, the tallies dataset consisted of the parcel numbers for parcels in the ballanced set of labels as desscrbed above, the value corresponding to blighted or not blighted, and 14 variables providing such tallies. As indicated in the following summary statistics, the dataset consists of 4283 rows.

```{r, message = FALSE}

library(tidyverse)
complete_tally_set <- read_rds("calculated_tallies.rds")
summary(complete_tally_set)

```

Further details about this dataset (or example, the manner in which the crime-incident data was dived into violent crimes, property crimes, and nuiscance crimes), including the code that was used in its construction, can be found at https://stuartbarnum.github.io/Detroit-Demolitions/Detriot_Draft_3.html.      In the end, because our analysis is restricted to dismantle permits and demolitions after May of 2016, the variable `later_recorded_crime_incents` was not used in our models. 

#### Models






In addition to the usual tasks of data cleaning, three fundamental challenges must be addressed before any predictive models are created. First, we construct a list buildings to be used in our models. This list will be based on the parcels of property on which the buildings stand. Essentially, the list of buildings will be a modified subset of all of the property parcels in Detroit: those that have or have had at least one building and satisfy a number of other constraints (perhaps including the constraint that there be only one building on the parcel). Second, we construct a set of labels---"blighted" or "not blighted"---to be assigned to each of the buildings. A building will be assigned one of these two labels on the basis of whether it is or was likely to be demolished. Third, we need an operational means of associating the various other blight-related aspects, such as crime rates and blight-related citations, with specific buildings. Although some of these associations will be made by means of parcel numbers, the primary means of association will be location (latitude and longitude) data, associated with the building by means of the `sf` (simple features) function `st_join`.
